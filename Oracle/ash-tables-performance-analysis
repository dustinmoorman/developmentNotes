Oracle Statistics
    - instance level statistics (awr, statspack)
        - too little detail => stop short of complete diagnosis
        - can be collected automatically
            - (passive)
    - trace level statistics (sql_trace)
        - too much detail => intrusive, hard to see big picture
        - must be enabled manually
        - need prior knowledge that problem exists
            - (reactive)

Solution: Active Session History
    - Sample session activity in the system including:
        - session id
        - wait event
        - sql id
        - object
    - always on for first fault analysis (passive)

Active session history
    - Sampled, detailed, non-intrusive activity data
    - part of 10g
    - on by default
    - licensed as part of the diagnostic pack
    
    - Samples 'Active' sessions every second
        - like doing "select * from v$session_wait" w/o sql
    - Writes into ASH buffer in SGA memory
        - 2MB per CPU, <= 5% shared_pool, 2% sga_target
    - 'Active' == Non-idle sessions
        - waiting on non-idle event or on CPU
    - Data volume based on activity
        - 10k sessions => 200 active sessions
        - oracle design goal: one hour activity in memory



-- size of the ash buffer
select * from v$sgastat where name like 'ASH buffers';

POOL        NAME        BYTES
----------- ----------- ------------
shared pool ASH buffers     65011712


-- sample time window
select min(sample_time), max(sample_time) from v$active_session_history;


Active Session History: On-disk

Captured as part of AWR snapshots
    - DBA_HIST_ACTIVE_SESS_HISTORY

Takes samples from in-memory ASH
    - 10 second samples

On-demand flush if required
    - Whenever circular buffer is 66% full
    - No missed data

Seven days history by default
    - Table is partitioned for easy purging


ASH Challenges: - Space

Memory Usage
    - Module, Action, Client_id (~50%)
    - Variable length rows

Disk Usage
    - Write 1 our of every 10 samples [to the AWR]
        - #mightBeAnIssue
Log Generation
    - Direct-path INSERTS

** awr - DBA_HIST_ACTIVE_SESS_HISTORY

ASH: Challenges - Time
    - Reader-writer concurrency
        - no consistent-read requirement
        - 1 writer -- multiple readers
        - readers go unlatched
    - Indexed on time **
        - Both v$ view and DBA_HIST view

What you can do with it
    - STATISTICAL analysis of where time was being spent by many different dimensions.
    - What was a session doing?
    - What does a SQL statement wait for?

Can decide on dimension after the event.

ASH Dimensions:

    - Session
    - Waits
        - Event, P1, P2, P3
    - SQL 
        - sql_id, Opcode, Plan_hash
    - Objects
        - Object#, File#, Block#
    - Application
        - Program, Module, Action, Client_id, Service
    - Combinations of the above.

Accessing ASH data *********************
    - Dump to trace file
    - v$active_session_history
    - DBA_HIST_ACTIVE_SESS_HISTORY
    - ASH report
    - EM diagnostic pack (unavail)

Dumping ASH to file

> oradebug setmypid
> oradebug dump ashdump 10
> alter session set events 'immediate trace name ashdump level 10';

10 = minutes of history you want to dump,
generated file can be loaded into db using supplied control file


rdmbs/demo/ashldr.ctl



v$active_session_history

- gives most recent data first
- control+C or 'set pause on'
- Simpleash.sql

Searching through the ASHes

- "group by"s and "count(*)"s
    - proxy for non-idle elapsed time
    - proportions of actual time spent
- can analyze any time slice
- more samples = more accurate results




TOP SQL --- Highly valuable

select sql_id, count(*), round(count(*)/sum(count(*)) over (), 2) pctload 
from v$active_session_history 
where sample_time > sysdate - 1/24/60
    and  session_type <> 'BACKGROUND'
group by sql_id
order by count(*) desc;


^ ^ ^ ^ most active sql in the past minute

TOP IO SQL

select * ash.sql_id, count(*)
from v$active_session_history ash,
    v$event_name evt
where ash.sample_time > sysdate - 1/24/60
    and ash.session_state = 'WAITING'
    and ash.event_id = evt.event_id
    and evt.wait_class = 'User I/O'
group by sql_id
order by count(*) desc;

^ ^ ^ ^ ^ ^ ^ returns SQL spending most time doing I/Os

Similarly, can do Top Sessions, Top Files, Top Objects





